# Core Web Vitals â€” Claude Skill

Audit website performance using Google's Core Web Vitals (CrUX field data) and [PageSpeed Insights API](https://developers.google.com/speed/docs/insights/v5/get-started). Works as a skill for Claude Code, OpenClaw, Codex, or any AI agent that supports SKILL.md.

## Features

- **Single URL** â€” Check one site, get formatted CWV results
- **Compare** â€” Two URLs side-by-side with winner highlighted per metric
- **Batch** â€” Paste multiple URLs, get results for all
- **Local measurement** â€” Measure CWV locally using Puppeteer (no API quota needed)
- **Google Sheet** â€” Point at a sheet with URLs in column A, auto-fills metrics with color-coded conditional formatting
- **CrUX field data** preferred (real user metrics from Chrome UX Report)
- **Lab data** fallback when CrUX unavailable
- **Browser scraping** fallback for API errors (loads web.dev via headless browser)
- **Parallel processing** â€” 4 concurrent workers by default
- **No pip dependencies** â€” Uses Python stdlib only

## Metrics

### Core Web Vitals (Field-Comparable)

These metrics work in both API mode (CrUX field data) and local mode (lab measurement):

| Metric | Good | Needs Improvement | Poor |
|--------|------|-------------------|------|
| LCP (Largest Contentful Paint) | â‰¤ 2.5s | 2.5â€“4.0s | > 4.0s |
| CLS (Cumulative Layout Shift) | â‰¤ 0.1 | 0.1â€“0.25 | > 0.25 |
| FCP (First Contentful Paint) | â‰¤ 1.8s | 1.8â€“3.0s | > 3.0s |
| TTFB (Time to First Byte) | â‰¤ 0.8s | 0.8â€“1.8s | > 1.8s |

### INP (API Mode Only)

| Metric | Good | Needs Improvement | Poor |
|--------|------|-------------------|------|
| INP (Interaction to Next Paint) | â‰¤ 200ms | 200â€“500ms | > 500ms |

**âš ï¸ Why is INP not available in local mode?**

INP requires `PerformanceEventTiming` entries generated by **real user interactions**. Puppeteer's synthetic events (click, keyboard, pointer events) do not generate these browser API entries, even when dispatched via Chrome DevTools Protocol. This is a fundamental limitation of headless browser testing, not a bug in this tool.

Even Google's Lighthouse doesn't measure INP in lab tests â€” instead, it uses **Total Blocking Time (TBT)** as a proxy metric for interactivity. Local mode follows the same approach.

**Where to get INP data:**
- **API mode** (CrUX field data) â€” Real user metrics from Chrome UX Report
- **Production sites only** â€” Must have 28 days of Chrome user data
- **Real User Monitoring (RUM)** â€” Implement web-vitals library on your live site

### Lab-Only Metrics (Local Mode)

These metrics are calculated from synthetic testing and provide insights into performance bottlenecks:

| Metric | Good | Needs Improvement | Poor |
|--------|------|-------------------|------|
| TBT (Total Blocking Time) | â‰¤ 200ms | 200â€“600ms | > 600ms |
| SI (Speed Index) | â‰¤ 3400ms | 3400â€“5800ms | > 5800ms |
| TTI (Time to Interactive) | â‰¤ 3800ms | 3800â€“7300ms | > 7300ms |

**What do these mean?**
- **TBT:** Total time the main thread was blocked by long tasks (>50ms) between FCP and TTI
- **SI:** How quickly the page contents are visually populated (lower is better)
- **TTI:** When the page becomes fully interactive (main thread has a 5-second quiet window)

## Prerequisites

### 1. PageSpeed Insights API Key
1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a project (or select existing)
3. Enable the **PageSpeed Insights API**: [Enable here](https://console.cloud.google.com/apis/library/pagespeedonline.googleapis.com)
4. Go to **APIs & Services â†’ Credentials â†’ Create Credentials â†’ API Key**
5. Copy the example env file and add your key:
   ```bash
   cp .env.example .env
   ```
6. Edit `.env` and replace `your_api_key_here` with your actual key
7. The scripts auto-load `.env` â€” no manual export needed

### 2. Google Sheets Access (only needed for Google Sheet mode)

*Not required for single URL or batch mode â€” those just need the PageSpeed API key above.*

**Option A: Service Account (recommended for portability)**
1. In Google Cloud Console, go to **IAM & Admin â†’ Service Accounts**
2. Click **Create Service Account**, give it a name, click **Done**
3. Click the service account â†’ **Keys â†’ Add Key â†’ Create new key â†’ JSON**
4. Save the downloaded JSON file (e.g., `service-account.json`)
5. **Share your Google Sheet** with the service account email (the `client_email` in the JSON) â€” give it **Editor** access

**Option B: gog CLI**
- Install and authenticate [gog CLI](https://github.com/openclaw/gog) â€” a Google Workspace CLI for Gmail, Calendar, Drive, and Sheets
- Use `--account your@email.com` instead of `--credentials`

### 3. Python 3.8+

No pip dependencies required â€” uses Python standard library only. Requires `openssl` CLI for service account JWT signing.

## Usage

### Local Mode (No API Needed)

Measure Core Web Vitals locally using Puppeteer + web-vitals library. No PageSpeed API key required!

**Install dependencies:**
```bash
cd /path/to/skills/core-web-vitals
npm install puppeteer web-vitals
```

**Usage:**
```bash
# Desktop only
python3 scripts/pagespeed-single.py --local example.com

# Desktop + Mobile (with network throttling)
python3 scripts/pagespeed-single.py --local --mobile example.com

# Compare two sites
python3 scripts/pagespeed-single.py --local site-a.com site-b.com

# JSON output
python3 scripts/pagespeed-single.py --local --json example.com
```

**Output:**
```
ðŸŒ dyode.com â€” CWV: Local Measurement

ðŸ“± Mobile *(Local (Puppeteer))*:
  CWV: LCP: 4.3s ðŸ”´ | CLS: 0.31 ðŸ”´ | FCP: 1.6s ðŸŸ¢ | TTFB: 0.1s ðŸŸ¢
  Lab: TBT: 450ms ðŸŸ¡ | SI: 2880ms ðŸŸ¢ | TTI: 5.2s ðŸŸ¡
ðŸ–¥ï¸ Desktop *(Local (Puppeteer))*:
  CWV: LCP: 0.6s ðŸŸ¢ | CLS: 0.00 ðŸŸ¢ | FCP: 0.6s ðŸŸ¢ | TTFB: 0.2s ðŸŸ¢
  Lab: TBT: 150ms ðŸŸ¢ | SI: 1080ms ðŸŸ¢ | TTI: 1.8s ðŸŸ¢

ðŸ“Š Data Source: Local (Puppeteer)
```

**Features:**
- Injects web-vitals library via `evaluateOnNewDocument` before page load
- Collects **CWV metrics:** LCP, FCP, CLS, TTFB
- Calculates **lab metrics:** TBT (Total Blocking Time), SI (Speed Index), TTI (Time to Interactive)
- **NO INP** â€” not measurable with synthetic events (see "Why is INP not available?" above)
- Mobile emulation with 3G network throttling + 4x CPU slowdown
- Same output format as API mode for consistency
- Works in compare and batch modes

**Why use local mode?**
- No API quota limits
- Faster for batch measurements (no API rate limits)
- Test sites behind auth/firewall
- Measure preview URLs (Shopify themes, staging environments)
- Get **bonus lab metrics** (TBT, SI, TTI) not available in CrUX field data

**Limitations:**
- **INP not available** â€” requires real user interactions (use API mode for INP)
- Results may vary slightly between runs
- Mobile throttling is simulated, not real device performance
- Lab metrics measure synthetic load, not real-world field performance

### Example Prompts

When this skill is installed, your AI agent will automatically use it when you ask about site performance:

**Single URL:**
> `/core-web-vitals rothys.com`
> or: "Check the Core Web Vitals for rothys.com"

```
ðŸŒ rothys.com â€” CWV: AVERAGE ðŸŸ¡

ðŸ“± Mobile:
  LCP: 2.2s ðŸŸ¢ | CLS: 0.00 ðŸŸ¢ | INP: 138ms ðŸŸ¢
  FCP: 2.0s ðŸŸ¡ | TTFB: 0.5s ðŸŸ¢

ðŸ–¥ï¸ Desktop:
  LCP: 2.7s ðŸŸ¡ | CLS: 0.01 ðŸŸ¢ | INP: 73ms ðŸŸ¢
  FCP: 1.8s ðŸŸ¢ | TTFB: 0.4s ðŸŸ¢

ðŸ“Š Data: CrUX field (28-day p75)
```

**Compare two sites:**
> `/core-web-vitals rothys.com, skims.com`
> or: "Compare the performance of skims.com vs rothys.com"

```
âš”ï¸ CWV Comparison: rothys.com vs skims.com

| Metric       | rothys.com  | skims.com   | Winner     |
|--------------|-------------|-------------|------------|
| ðŸ“± M-LCP    | 2.2s ðŸŸ¢    | 2.1s ðŸŸ¢    | âœ… skims   |
| ðŸ“± M-CLS    | 0.00 ðŸŸ¢    | 0.26 ðŸ”´    | âœ… rothys  |
| ðŸ“± M-INP    | 138ms ðŸŸ¢   | 249ms ðŸŸ¡   | âœ… rothys  |
| ðŸ“± M-FCP    | 2.0s ðŸŸ¡    | 1.4s ðŸŸ¢    | âœ… skims   |
| ðŸ“± M-TTFB   | 0.5s ðŸŸ¢    | 0.8s ðŸŸ¢    | âœ… rothys  |
| ðŸ–¥ï¸ D-LCP   | 2.7s ðŸŸ¡    | 1.8s ðŸŸ¢    | âœ… skims   |
| ðŸ–¥ï¸ D-CLS   | 0.01 ðŸŸ¢    | 0.03 ðŸŸ¢    | âœ… rothys  |
| ðŸ–¥ï¸ D-INP   | 73ms ðŸŸ¢    | 95ms ðŸŸ¢    | âœ… rothys  |
| ðŸ–¥ï¸ D-FCP   | 1.8s ðŸŸ¢    | 1.2s ðŸŸ¢    | âœ… skims   |
| ðŸ–¥ï¸ D-TTFB  | 0.4s ðŸŸ¢    | 0.5s ðŸŸ¢    | âœ… rothys  |

Overall: rothys.com wins 6/10 metrics
CWV: rothys AVERAGE ðŸŸ¡ vs skims FAILED ðŸ”´
```

**Shopify Theme QA (compare before/after theme changes):**
> `/core-web-vitals brandname.myshopify.com?preview_theme_id=111111, brandname.myshopify.com?preview_theme_id=222222`
> or: "Compare CWV before and after theme changes for brandname.myshopify.com"

```
ðŸ” Shopify Theme QA: brandname.myshopify.com

| Metric       | Before (111111) | After (222222) | Change     |
|--------------|----------------|----------------|------------|
| ðŸ“± M-LCP    | 2.1s ðŸŸ¢       | 2.8s ðŸŸ¡       | âš ï¸ +0.7s  |
| ðŸ“± M-CLS    | 0.05 ðŸŸ¢       | 0.12 ðŸŸ¡       | âš ï¸ +0.07  |
| ðŸ“± M-INP    | 150ms ðŸŸ¢      | 145ms ðŸŸ¢      | ðŸŽ‰ -5ms   |
| ...          |                |                |            |

Summary: 2 regressions âš ï¸ | 1 improvement ðŸŽ‰ | 7 unchanged
ðŸš¨ Do not publish â€” CWV regression detected (LCP crossed greenâ†’yellow)
```

*Why two preview URLs?* Shopify preview themes are inherently slower than the live site due to preview mode overhead. Comparing the live URL against a preview URL would always show false regressions. Instead, compare the **production theme in preview mode** (before) against the **development theme in preview mode** (after) for an apples-to-apples comparison that isolates the actual impact of your code changes.

**Local Mode (single URL, no API needed):**
> `/core-web-vitals --local agjeans.com`
> or: "Run a local CWV test on agjeans.com"

```
ðŸŒ agjeans.com â€” CWV: Local Measurement

ðŸ–¥ï¸ Desktop (Local (Puppeteer)):
  CWV: LCP: 0.8s ðŸŸ¢ | CLS: 0.06 ðŸŸ¢ | FCP: 0.7s ðŸŸ¢ | TTFB: 0.0s ðŸŸ¢
  Lab: TBT: 0ms ðŸŸ¢ | SI: 744ms ðŸŸ¢ | TTI: 1.5s ðŸŸ¢

ðŸ“Š Data Source: Local (Puppeteer)
```

**Local Mode with Mobile (throttled 3G + CPU slowdown):**
> `/core-web-vitals --local --mobile agjeans.com`
> or: "Run local CWV test on agjeans.com including mobile"

```
ðŸŒ agjeans.com â€” CWV: Local Measurement

ðŸ“± Mobile (Local (Puppeteer)):
  CWV: LCP: 1.3s ðŸŸ¢ | CLS: 0.00 ðŸŸ¢ | FCP: 0.8s ðŸŸ¢ | TTFB: N/A â€”
  Lab: TBT: 0ms ðŸŸ¢ | SI: 1078ms ðŸŸ¢ | TTI: 0.8s ðŸŸ¢
ðŸ–¥ï¸ Desktop (Local (Puppeteer)):
  CWV: LCP: 0.5s ðŸŸ¢ | CLS: 0.05 ðŸŸ¢ | FCP: 0.5s ðŸŸ¢ | TTFB: 0.0s ðŸŸ¢
  Lab: TBT: 0ms ðŸŸ¢ | SI: 536ms ðŸŸ¢ | TTI: 1.5s ðŸŸ¢

ðŸ“Š Data Source: Local (Puppeteer)
```

**Local Mode Compare (two sites):**
> `/core-web-vitals --local dyode.com, pacsun.com`
> or: "Compare dyode.com vs pacsun.com locally"

```
âš”ï¸ CWV Comparison: dyode.com vs pacsun.com (Local)

| Metric    | dyode.com     | pacsun.com    | Winner        |
|-----------|---------------|---------------|---------------|
| ðŸ–¥ï¸ LCP   | 0.8s ðŸŸ¢      | 0.6s ðŸŸ¢      | âœ… pacsun.com |
| ðŸ–¥ï¸ CLS   | 0.00 ðŸŸ¢      | 0.00 ðŸŸ¢      | Tie           |
| ðŸ–¥ï¸ FCP   | 0.7s ðŸŸ¢      | 0.6s ðŸŸ¢      | âœ… pacsun.com |
| ðŸ–¥ï¸ TTFB  | 0.3s ðŸŸ¢      | 0.3s ðŸŸ¢      | âœ… dyode.com  |

Overall: pacsun.com wins 2/3 metrics
```

**Batch (multiple URLs):**
> `/core-web-vitals dyode.com, rothys.com, allbirds.com`
> or: "Check CWV for dyode.com, rothys.com, and allbirds.com"

```
ðŸ“Š Batch CWV Results

| Site          | M-LCP | M-CLS | M-INP  | M-FCP | CWV     |
|---------------|-------|-------|--------|-------|---------|
| dyode.com     | 1.8s ðŸŸ¢ | 0.02 ðŸŸ¢ | 95ms ðŸŸ¢ | 1.2s ðŸŸ¢ | FAST âœ…  |
| rothys.com    | 2.2s ðŸŸ¢ | 0.00 ðŸŸ¢ | 138ms ðŸŸ¢ | 2.0s ðŸŸ¡ | AVG ðŸŸ¡  |
| allbirds.com  | 3.1s ðŸŸ¡ | 0.08 ðŸŸ¢ | 210ms ðŸŸ¡ | 2.4s ðŸŸ¡ | SLOW ðŸ”´ |

ðŸ“Š Data: CrUX field (28-day p75) | Mobile results shown
```

**Google Sheet:**
> `/core-web-vitals https://docs.google.com/spreadsheets/d/abc123/edit`
> or: "Run PageSpeed audits on all URLs in this sheet: https://docs.google.com/spreadsheets/d/abc123/edit"

```
ðŸ“‹ Starting bulk CWV audit...
  Sheet: "Sheet1" | 1,305 URLs found
  Workers: 4 parallel | Est. time: ~8 hours
  Auth: Service account (cwv-bot@project.iam.gserviceaccount.com)

  Writing results to columns B-N with conditional formatting.
  Progress updates every 25 URLs.

  âœ… Complete: 1,247 processed | 42 CrUX field | 1,163 lab | 42 errors
  ðŸ”„ Running browser retry on 42 error rows...
```

### Google Sheet Mode

Your Google Sheet must have URLs in **column A** starting at row 2 (row 1 = headers).

```bash
# With service account
python3 scripts/pagespeed-bulk.py SPREADSHEET_ID --credentials service-account.json

# With gog CLI
python3 scripts/pagespeed-bulk.py SPREADSHEET_ID --account you@example.com

# Resume from a specific index
python3 scripts/pagespeed-bulk.py SPREADSHEET_ID --credentials sa.json --start 150

# Custom worker count
python3 scripts/pagespeed-bulk.py SPREADSHEET_ID --credentials sa.json --workers 6

# Override API key
python3 scripts/pagespeed-bulk.py SPREADSHEET_ID --credentials sa.json --api-key YOUR_KEY
```

The script writes results to columns Bâ€“N:

| Column | Metric |
|--------|--------|
| B | Mobile LCP (s) |
| C | Mobile CLS |
| D | Mobile INP (ms) |
| E | Mobile FCP (s) |
| F | Mobile TTFB (s) |
| G | Mobile CWV Assessment |
| H | Desktop LCP (s) |
| I | Desktop CLS |
| J | Desktop INP (ms) |
| K | Desktop FCP (s) |
| L | Desktop TTFB (s) |
| M | Desktop CWV Assessment |
| N | Data Source (Field/Lab/Web.dev/Error) |

### Retry Errors via Browser Scraping

After the bulk scan, some URLs may show ERROR (API timeouts on heavy sites). Retry by scraping web.dev:

```bash
python3 scripts/pagespeed-retry-browser.py SPREADSHEET_ID --credentials sa.json
```

*Note: Browser retry requires `agent-browser` CLI.*

## Performance

- ~2.5 URLs/minute with 4 parallel workers
- API rate limit: 25,000 requests/day, 400/100s (not the bottleneck)
- Bottleneck is Google's Lighthouse analysis time (30-90s per URL per strategy)
- 1,000 URLs â‰ˆ 6-7 hours

## Roadmap

Future improvements under consideration:

- [ ] **Historical tracking** â€” Run the same URLs weekly, store results, show trends ("LCP improved 0.3s since last week")
- [ ] **Lighthouse recommendations** â€” Parse top 3 actionable audit items (render-blocking resources, image optimization, etc.)
- [ ] **Threshold alerts** â€” Flag URLs that crossed from green to yellow/red since last run
- [ ] **CSV/Markdown export** â€” Alternative output formats for batch mode beyond Google Sheets
- [ ] **Progress spinner** â€” Better visual feedback during long-running API calls

Have an idea? [Open an issue](https://github.com/dyodeinc/claude-skill-pagespeed/issues).

## License

MIT
